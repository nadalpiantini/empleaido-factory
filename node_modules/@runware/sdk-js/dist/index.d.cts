declare enum Environment {
    PRODUCTION = "PRODUCTION",
    DEVELOPMENT = "DEVELOPMENT",
    TEST = "TEST"
}
declare enum SdkType {
    CLIENT = "CLIENT",
    SERVER = "SERVER"
}
declare enum ETaskType {
    IMAGE_INFERENCE = "imageInference",
    IMAGE_UPLOAD = "imageUpload",
    UPSCALE = "upscale",
    REMOVE_BACKGROUND = "removeBackground",
    VIDEO_INFERENCE = "videoInference",
    CAPTION = "caption",
    AUDIO_INFERENCE = "audioInference",
    GET_RESPONSE = "getResponse",
    PHOTO_MAKER = "photoMaker",
    IMAGE_CONTROL_NET_PRE_PROCESS = "imageControlNetPreProcess",
    IMAGE_MASKING = "imageMasking",
    PROMPT_ENHANCE = "promptEnhance",
    AUTHENTICATION = "authentication",
    MODEL_UPLOAD = "modelUpload",
    MODEL_SEARCH = "modelSearch",
    MEDIA_STORAGE = "mediaStorage",
    VECTORIZE = "vectorize"
}
type RunwareBaseType = {
    apiKey: string;
    url?: string;
    shouldReconnect?: boolean;
    globalMaxRetries?: number;
    timeoutDuration?: number;
};
type IOutputType = "base64Data" | "dataURI" | "URL";
type IOutputFormat = "JPG" | "PNG" | "WEBP";
type IVideoOutputFormat = "MP4" | "WEBM" | "MOV";
type IAudioOutputFormat = "MP3";
interface IAdditionalResponsePayload {
    includePayload?: boolean;
    includeGenerationTime?: boolean;
}
interface IImage {
    taskType: ETaskType;
    imageUUID?: string;
    inputImageUUID?: string;
    taskUUID: string;
    status: string;
    imageURL?: string;
    imageBase64Data?: string;
    imageDataURI?: string;
    NSFWContent?: boolean;
    cost?: number;
    seed: number;
    mediaUUID?: string;
    mediaURL?: string;
}
interface ITextToImage extends IImage {
    positivePrompt?: string;
    negativePrompt?: string;
}
interface IVideoToImage {
    taskUUID: string;
    taskType: string;
    status: string;
    videoUUID?: string;
    cost?: number;
    seed?: number;
    videoURL?: string;
}
interface IControlNetImage {
    taskUUID: string;
    inputImageUUID: string;
    guideImageUUID: string;
    guideImageURL?: string;
    guideImageBase64Data?: string;
    guideImageDataURI?: string;
    cost?: number;
}
interface ILora {
    model: string | number;
    weight: number;
}
declare enum EControlMode {
    BALANCED = "balanced",
    PROMPT = "prompt",
    CONTROL_NET = "controlnet"
}
type IControlNetGeneral = {
    model: string;
    guideImage: string | File;
    weight?: number;
    startStep?: number;
    startStepPercentage?: number;
    endStep?: number;
    endStepPercentage?: number;
    controlMode: EControlMode;
};
type IControlNetPreprocess = {
    inputImage: string | File;
    preProcessorType: EPreProcessorGroup;
    height?: number;
    width?: number;
    outputType?: IOutputType;
    outputFormat?: IOutputFormat;
    highThresholdCanny?: number;
    lowThresholdCanny?: number;
    includeHandsAndFaceOpenPose?: boolean;
    includeCost?: boolean;
    outputQuality?: number;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
} & IAdditionalResponsePayload;
type IControlNet = IControlNetGeneral;
type IControlNetWithUUID = Omit<IControlNet, "guideImage"> & {
    guideImage?: string;
};
interface IError {
    error: boolean;
    errorMessage: string;
    taskUUID: string;
}
type TPromptWeighting = "compel" | "sdEmbeds";
interface IRequestImage extends IAdditionalResponsePayload {
    outputType?: IOutputType;
    outputFormat?: IOutputFormat;
    uploadEndpoint?: string;
    checkNSFW?: boolean;
    positivePrompt: string;
    negativePrompt?: string;
    seedImage?: File | string;
    maskImage?: File | string;
    strength?: number;
    height?: number;
    width?: number;
    model: number | string;
    steps?: number;
    scheduler?: string;
    seed?: number;
    maskMargin?: number;
    CFGScale?: number;
    clipSkip?: number;
    /**
     * @deprecated The usePromptWeighting should not be used, use promptWeighting instead
     */
    usePromptWeighting?: boolean;
    promptWeighting?: TPromptWeighting;
    numberResults?: number;
    includeCost?: boolean;
    outputQuality?: number;
    controlNet?: IControlNet[];
    lora?: ILora[];
    embeddings?: IEmbedding[];
    ipAdapters?: IipAdapter[];
    providerSettings?: IProviderSettings;
    outpaint?: IOutpaint;
    refiner?: IRefiner;
    acceleratorOptions?: TAcceleratorOptions;
    advancedFeatures?: {
        layerDiffuse: boolean;
    };
    referenceImages?: string[];
    customTaskUUID?: string;
    onPartialImages?: (images: IImage[], error?: IError) => void;
    retry?: number;
    [key: string]: any;
}
type TAcceleratorOptions = {
    teaCache: boolean;
    teaCacheDistance: number;
} | {
    deepCache: boolean;
    deepCacheInterval: number;
    deepCacheBranchId: number;
};
interface IOutpaint {
    top?: number;
    bottom?: number;
    right?: number;
    left?: number;
    blur?: number;
}
interface IEmbedding {
    model: string;
    weight: number;
}
interface IipAdapter {
    model: string;
    weight: number;
    guideImage: string;
}
interface IBflProviderSettings {
    promptUpsampling?: boolean;
    safetyTolerance?: number;
    raw?: boolean;
}
type ProviderSettings = {
    bfl: IBflProviderSettings;
};
type IProviderSettings = RequireOnlyOne<ProviderSettings, keyof ProviderSettings>;
interface IRefiner {
    model: string;
    startStep?: number;
    startStepPercentage?: number;
}
interface IRequestImageToText extends IAdditionalResponsePayload {
    model?: string;
    inputImage?: File | string;
    inputs?: {
        video?: InputsValue;
    } & {
        [key: string]: unknown;
    };
    includeCost?: boolean;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
    deliveryMethod?: string;
    skipResponse?: boolean;
}
interface IImageToText {
    taskType: ETaskType;
    taskUUID: string;
    status: string;
    text: string;
    cost?: number;
}
interface IRemoveImageBackground extends IRequestImageToText {
    outputType?: IOutputType;
    outputFormat?: IOutputFormat | "MP4" | "WEBM" | "MOV";
    model: string;
    inputs?: {
        video?: InputsValue;
        image?: InputsValue;
    };
    settings?: {
        rgba?: number[];
        postProcessMask?: boolean;
        returnOnlyMask?: boolean;
        alphaMatting?: boolean;
        alphaMattingForegroundThreshold?: number;
        alphaMattingBackgroundThreshold?: number;
        alphaMattingErodeSize?: number;
    };
    includeCost?: boolean;
    outputQuality?: number;
    retry?: number;
    skipResponse?: boolean;
    deliveryMethod?: string;
}
type InputsValue = string | Record<string, unknown>;
interface IRequestVideo extends IRequestImageToText {
    outputType?: IOutputType;
    outputFormat?: IVideoOutputFormat;
    outputQuality?: number;
    uploadEndpoint?: string;
    checkNSFW?: boolean;
    includeCost?: boolean;
    positivePrompt?: string;
    negativePrompt?: string;
    model: string;
    steps?: number;
    CFGScale?: number;
    seed?: number;
    duration?: number;
    fps?: number;
    width?: number;
    height?: number;
    numberResults?: number;
    inputAudios?: string[];
    referenceVideos?: string[];
    inputs?: {
        image?: InputsValue;
        images?: InputsValue[];
        audio?: InputsValue;
        audios?: InputsValue[];
        mask?: InputsValue[];
        reference?: InputsValue;
        references?: InputsValue[];
    } & {
        [key: string]: unknown;
    };
    speech?: {
        voice: string;
        text: string;
    };
    skipResponse?: boolean;
    customTaskUUID?: string;
    retry?: number;
    [key: string]: any;
}
interface IAudio {
    taskUUID: string;
    taskType: string;
    status: string;
    audioUUID?: string;
    audioURL?: string;
    audioBase64Data?: string;
    audioDataURI?: string;
    cost?: number;
}
interface IRequestAudio {
    model: string;
    numberResults?: number;
    outputType?: IOutputType;
    outputFormat?: IAudioOutputFormat;
    uploadEndpoint?: string;
    includeCost?: boolean;
    positivePrompt?: string;
    duration?: number;
    audioSettings?: {
        sampleRate?: number;
        bitrate?: number;
    } & {
        [key: string]: unknown;
    };
    inputs?: {
        video?: InputsValue;
    } & {
        [key: string]: unknown;
    };
    deliveryMethod?: string;
    taskUUID?: string;
    customTaskUUID?: string;
    skipResponse?: boolean;
    retry?: number;
    [key: string]: unknown;
}
interface IAsyncResults {
    taskUUID: string;
    onPartialImages?: (images: IImage[], error?: IError) => void;
}
interface IRemoveImage {
    taskType: ETaskType;
    taskUUID: string;
    status: string;
    imageUUID?: string;
    mediaUUID?: string;
    mediaURL?: string;
    videoUUID?: string;
    inputImageUUID: string;
    imageURL?: string;
    imageBase64Data?: string;
    imageDataURI?: string;
    cost?: number;
}
interface IPromptEnhancer extends IAdditionalResponsePayload {
    promptMaxLength?: number;
    promptVersions?: number;
    prompt: string;
    includeCost?: boolean;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
}
interface IEnhancedPrompt extends IImageToText {
}
interface IUpscaleGan extends IAdditionalResponsePayload {
    inputImage?: File | string;
    upscaleFactor: number;
    outputType?: IOutputType;
    outputFormat?: IOutputFormat | "MP4" | "WEBM" | "MOV";
    includeCost?: boolean;
    outputQuality?: number;
    inputs?: {
        video?: InputsValue;
        image?: InputsValue;
    } & {
        [key: string]: unknown;
    };
    model?: string;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
    skipResponse?: boolean;
    deliveryMethod?: string;
}
type ReconnectingWebsocketProps = {
    addEventListener: (type: string, listener: EventListener, options: any) => void;
    send: (data: any) => void;
} & WebSocket;
type UploadImageType = {
    imageURL: string;
    imageUUID: string;
    taskUUID: string;
    taskType: ETaskType;
};
type GetWithPromiseCallBackType = ({ resolve, reject, intervalId, }: {
    resolve: <T>(value: T) => void;
    reject: <T>(value: T) => void;
    intervalId: any;
}) => boolean | undefined;
type GetWithPromiseAsyncCallBackType = ({ resolve, reject, intervalId, }: {
    resolve: <T>(value: T) => void;
    reject: <T>(value: T) => void;
    intervalId: any;
}) => any;
declare enum EPreProcessorGroup {
    "canny" = "canny",
    "depth" = "depth",
    "mlsd" = "mlsd",
    "normalbae" = "normalbae",
    "openpose" = "openpose",
    "tile" = "tile",
    "seg" = "seg",
    "lineart" = "lineart",
    "lineart_anime" = "lineart_anime",
    "shuffle" = "shuffle",
    "scribble" = "scribble",
    "softedge" = "softedge"
}
declare enum EPreProcessor {
    "canny" = "canny",
    "depth_leres" = "depth_leres",
    "depth_midas" = "depth_midas",
    "depth_zoe" = "depth_zoe",
    "inpaint_global_harmonious" = "inpaint_global_harmonious",
    "lineart_anime" = "lineart_anime",
    "lineart_coarse" = "lineart_coarse",
    "lineart_realistic" = "lineart_realistic",
    "lineart_standard" = "lineart_standard",
    "mlsd" = "mlsd",
    "normal_bae" = "normal_bae",
    "scribble_hed" = "scribble_hed",
    "scribble_pidinet" = "scribble_pidinet",
    "seg_ofade20k" = "seg_ofade20k",
    "seg_ofcoco" = "seg_ofcoco",
    "seg_ufade20k" = "seg_ufade20k",
    "shuffle" = "shuffle",
    "softedge_hed" = "softedge_hed",
    "softedge_hedsafe" = "softedge_hedsafe",
    "softedge_pidinet" = "softedge_pidinet",
    "softedge_pidisafe" = "softedge_pidisafe",
    "tile_gaussian" = "tile_gaussian",
    "openpose" = "openpose",
    "openpose_face" = "openpose_face",
    "openpose_faceonly" = "openpose_faceonly",
    "openpose_full" = "openpose_full",
    "openpose_hand" = "openpose_hand"
}
declare enum EOpenPosePreProcessor {
    "openpose" = "openpose",
    "openpose_face" = "openpose_face",
    "openpose_faceonly" = "openpose_faceonly",
    "openpose_full" = "openpose_full",
    "openpose_hand" = "openpose_hand"
}
type RequireAtLeastOne<T, Keys extends keyof T = keyof T> = Pick<T, Exclude<keyof T, Keys>> & {
    [K in Keys]-?: Required<Pick<T, K>> & Partial<Pick<T, Exclude<Keys, K>>>;
}[Keys];
type RequireOnlyOne<T, Keys extends keyof T = keyof T> = Pick<T, Exclude<keyof T, Keys>> & {
    [K in Keys]-?: Required<Pick<T, K>> & Partial<Record<Exclude<Keys, K>, undefined>>;
}[Keys];
type ListenerType = {
    key: string;
    listener: (msg: any) => void;
    groupKey?: string;
};
interface IAddModelResponse {
    status: string;
    message: string;
    taskUUID: string;
    air: string;
    taskType: string;
}
interface IErrorResponse {
    code: string;
    message: string;
    parameter: string;
    type: string;
    documentation: string;
    taskUUID: string;
    min?: number;
    max?: number;
    default?: string | number;
}
type TAddModelBaseType = {
    air: string;
    name: string;
    downloadURL: string;
    uniqueIdentifier: string;
    version: string;
    format: EModelFormat;
    architecture: EModelArchitecture;
    heroImageURL?: string;
    tags?: string[];
    shortDescription?: string;
    comment?: string;
    private: boolean;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
    onUploadStream?: (response?: IAddModelResponse, error?: IErrorResponse) => void;
};
type TAddModelControlNet = {
    category: "controlnet";
    conditioning: EModelConditioning;
} & TAddModelBaseType;
type TAddModelCheckPoint = {
    category: "checkpoint";
    defaultCFGScale?: number;
    defaultStrength: number;
    defaultSteps?: number;
    defaultScheduler?: string;
    type: EModelType;
} & TAddModelBaseType;
type TAddModelLora = {
    category: "lora";
    defaultWeight: number;
    positiveTriggerWords?: string;
} & TAddModelBaseType;
type TAddModel = TAddModelCheckPoint | TAddModelControlNet | TAddModelLora;
type TPhotoMaker = {
    style: EPhotoMakerEnum;
    inputImages: string[];
    outputType?: string;
    outputFormat?: string;
    uploadEndpoint?: string;
    checkNSFW?: boolean;
    positivePrompt: string;
    negativePrompt?: string;
    strength?: number;
    height: number;
    width: number;
    model?: string;
    steps?: number;
    scheduler?: string;
    seed?: number;
    CFGScale?: number;
    clipSkip?: number;
    numberResults: number;
    includeCost?: boolean;
    outputQuality?: number;
    customTaskUUID?: string;
    taskUUID?: string;
    retry?: number;
    onPartialImages?: (images: IImage[], error?: IError) => void;
} & IAdditionalResponsePayload;
type TPhotoMakerResponse = {
    taskType: string;
    taskUUID: string;
    status: string;
    imageUUID: string;
    NSFWContent: boolean;
    cost: number;
    seed: number;
    imageURL: string;
    positivePrompt: string;
    negativePrompt?: string;
};
declare enum EModelFormat {
    safetensors = "safetensors",
    pickletensor = "pickletensor"
}
declare enum EModelArchitecture {
    flux1d = "flux1d",
    flux1s = "flux1s",
    pony = "pony",
    sdhyper = "sdhyper",
    sd1x = "sd1x",
    sd1xlcm = "sd1xlcm",
    sd3 = "sd3",
    sdxl = "sdxl",
    sdxllcm = "sdxllcm",
    sdxldistilled = "sdxldistilled",
    sdxlhyper = "sdxlhyper",
    sdxllightning = "sdxllightning",
    sdxlturbo = "sdxlturbo"
}
declare enum EModelType {
    base = "base",
    inpainting = "inpainting",
    pix2pix = "pix2pix"
}
declare enum EModelConditioning {
    canny = "canny",
    depth = "depth",
    qrcode = "qrcode",
    hed = "hed",
    scrible = "scrible",
    openpose = "openpose",
    seg = "segmentation",
    openmlsd = "openmlsd",
    softedge = "softedge",
    normal = "normal bae",
    shuffle = "shuffle",
    pix2pix = "pix2pix",
    inpaint = "inpaint",
    lineart = "line art",
    sketch = "sketch",
    inpaintdepth = "inpaint depth",
    tile = "tile",
    outfit = "outfit",
    blur = "blur",
    gray = "gray",
    lowquality = "low quality"
}
declare enum EPhotoMakerEnum {
    NoStyle = "No style",
    Cinematic = "Cinematic",
    DisneyCharacter = "Disney Character",
    DigitalArt = "Digital Art",
    Photographic = "Photographic",
    FantasyArt = "Fantasy art",
    Neonpunk = "Neonpunk",
    Enhance = "Enhance",
    ComicBook = "Comic book",
    Lowpoly = "Lowpoly",
    LineArt = "Line art"
}
type TModelSearch = {
    search?: string;
    tags?: string[];
    category?: "checkpoint" | "lora" | "controlnet";
    type?: string;
    architecture?: EModelArchitecture;
    conditioning?: string;
    visibility?: "public" | "private" | "all";
    limit?: number;
    offset?: number;
    customTaskUUID?: string;
    retry?: number;
} & {
    [key: string]: any;
};
type TModel = {
    air: string;
    name: string;
    version: string;
    category: string;
    architecture: string;
    tags: string[];
    heroImage: string;
    private: boolean;
    comment: string;
    type?: string;
    defaultWidth?: number;
    defaultHeight?: number;
    defaultSteps?: number;
    defaultScheduler?: string;
    defaultCFG?: number;
    defaultStrength: number;
    conditioning?: string;
    positiveTriggerWords?: string;
} & {
    [key: string]: any;
};
type TModelSearchResponse = {
    results: TModel[];
    taskUUID: string;
    taskType: string;
    totalResults: number;
};
type TImageMasking = {
    model: string;
    inputImage: string;
    confidence?: number;
    maskPadding?: number;
    maskBlur?: number;
    outputFormat?: string;
    outputType?: string;
    includeCost?: boolean;
    uploadEndpoint?: string;
    maxDetections?: number;
    outputQuality?: number;
    customTaskUUID?: string;
    retry?: number;
};
type TVectorize = {
    model: string;
    outputFormat?: string;
    outputType?: string;
    includeCost?: boolean;
    inputs: {
        image: string;
    };
    customTaskUUID?: string;
    retry?: number;
};
type TVectorizeResponse = {
    taskType: string;
    taskUUID: string;
    cost: number;
    imageURL: string;
};
type TImageUpload = {
    image: string;
    customTaskUUID?: string;
    retry?: number;
};
type TMediaStorage = {
    media: string;
    operation?: string;
    customTaskUUID?: string;
    retry?: number;
};
type TMediaStorageResponse = {
    taskType: string;
    taskUUID: string;
    mediaUUID: string;
};
type TImageUploadResponse = {
    image: string;
    taskUUID: string;
    imageUUID: number;
    imageURL: string;
};
type TImageMaskingResponse = {
    taskType: string;
    taskUUID: string;
    maskImageUUID: string;
    detections: [
        {
            x_min: number;
            y_min: number;
            x_max: number;
            y_max: number;
        }
    ];
    maskImageURL: string;
    cost: number;
};
type TServerError = {
    error: {
        code: string;
        message: string;
        parameter: string;
        type: string;
        taskType: string;
    };
};
type MediaUUID = {
    mediaUUID?: string;
    audioUUID?: string;
    imageUUID?: string;
    videoUUID?: string;
};

declare enum LISTEN_TO_MEDIA_KEY {
    REQUEST_IMAGES = "REQUEST_IMAGES",
    REQUEST_AUDIO = "REQUEST_AUDIO"
}

declare class RunwareBase {
    _ws: ReconnectingWebsocketProps | any;
    _listeners: ListenerType[];
    _apiKey: string;
    _url?: string;
    _globalMessages: Record<string, any>;
    _globalImages: IImage[];
    _globalError: IError | undefined;
    _connectionSessionUUID: string | undefined;
    _connectionError: TServerError | undefined;
    _sdkType: SdkType;
    _shouldReconnect: boolean;
    _globalMaxRetries: number;
    _timeoutDuration: number;
    ensureConnectionUUID: string | null;
    constructor({ apiKey, url, shouldReconnect, globalMaxRetries, timeoutDuration, }: RunwareBaseType);
    private getUniqueUUID;
    /**
     * Shared polling logic for async results.
     * @param taskUUID - The task UUID to poll for.
     * @param numberResults - Number of results expected.
     * @returns Promise resolving to array of results.
     */
    private pollForAsyncResults;
    static initialize(props: RunwareBaseType): Promise<RunwareBase>;
    protected isWebsocketReadyState: () => boolean;
    protected isInvalidAPIKey: () => boolean;
    protected addListener({ lis, groupKey, taskUUID, }: {
        lis: (v: any) => any;
        groupKey?: string;
        taskUUID: string;
    }): {
        destroy: () => void;
    };
    protected connect(): void;
    protected send: (msg: Object) => void;
    private destroy;
    private uploadImage;
    private listenToResponse;
    private listenToUpload;
    private globalListener;
    requestImages({ outputType, outputFormat, uploadEndpoint, checkNSFW, positivePrompt, negativePrompt, seedImage, maskImage, strength, height, width, model, steps, scheduler, seed, CFGScale, clipSkip, usePromptWeighting, promptWeighting, numberResults, onPartialImages, includeCost, customTaskUUID, taskUUID: _taskUUID, retry, refiner, maskMargin, outputQuality, controlNet, lora, embeddings, ipAdapters, providerSettings, outpaint, acceleratorOptions, advancedFeatures, referenceImages, includeGenerationTime, includePayload, ...rest }: IRequestImage, moreOptions?: Record<string, any>): Promise<ITextToImage[] | undefined>;
    imageInference(params: IRequestImage, moreOptions?: Record<string, any>): Promise<ITextToImage[] | undefined>;
    controlNetPreProcess: ({ inputImage, preProcessorType, height, width, outputType, outputFormat, highThresholdCanny, lowThresholdCanny, includeHandsAndFaceOpenPose, includeCost, outputQuality, customTaskUUID, taskUUID: _taskUUID, retry, includeGenerationTime, includePayload, }: IControlNetPreprocess) => Promise<IControlNetImage | null>;
    controlNetPreprocess: (params: IControlNetPreprocess) => Promise<IControlNetImage | null>;
    requestImageToText: ({ inputImage, inputs, includeCost, customTaskUUID, taskUUID: _taskUUID, retry, includePayload, includeGenerationTime, deliveryMethod, skipResponse, model, }: IRequestImageToText) => Promise<IImageToText>;
    caption: (params: IRequestImageToText) => Promise<IImageToText>;
    /**
     * Remove the background from an image or video.
     * @remark This method now supports the removeBackground type which can handle multiple media types such as image and video.
     * If you pass an `inputs` object with `inputs.image` or `inputs.video`, the response will contain `mediaUUID` and `mediaURL`.
     * If you pass `inputImage`, the response will contain `imageUUID` and `imageURL`.
     * @remark `imageUUID` is no longer guaranteed in the response. Use `mediaUUID` for new implementations.
     * @since 1.2.0
     * @returns {Promise<IRemoveImage>} If called with `inputs.image` or `inputs.video`, returns an object with `mediaUUID` and `mediaURL`. If called with `inputImage`, returns an object with `imageUUID` and `imageURL` (not guaranteed).
     */
    removeImageBackground: (payload: IRemoveImageBackground) => Promise<IRemoveImage>;
    removeBackground: (payload: IRemoveImageBackground) => Promise<IRemoveImage>;
    vectorize: (payload: TVectorize) => Promise<TVectorizeResponse>;
    videoInference: (payload: IRequestVideo) => Promise<IVideoToImage[] | IVideoToImage>;
    audioInference: (payload: IRequestAudio) => Promise<IAudio[] | IAudio>;
    getResponse: <T>(payload: IAsyncResults) => Promise<T[]>;
    /**
     * Upscale an image or video
     * @remark This method now supports the upscale type which can handle multiple media types such as image and video.
     * If you pass an `inputs` object with `inputs.image` or `inputs.video`, the response will contain `mediaUUID` and `mediaURL`.
     * If you pass `inputImage`, the response will contain `imageUUID` and `imageURL`.
     * @remark `imageUUID` is no longer guaranteed in the response. Use `mediaUUID` for new implementations.
     * @since 1.2.0
     * @returns {Promise<IImage>} If called with `inputs.image` or `inputs.video`, returns an object with `mediaUUID` and `mediaURL`. If called with `inputImage`, returns an object with `imageUUID` and `imageURL` (not guaranteed).
     */
    upscaleGan: ({ inputImage, inputs, model, upscaleFactor, outputType, outputFormat, includeCost, outputQuality, customTaskUUID, taskUUID: _taskUUID, retry, includeGenerationTime, includePayload, skipResponse, deliveryMethod }: IUpscaleGan) => Promise<IImage>;
    upscale: (params: IUpscaleGan) => Promise<IImage>;
    enhancePrompt: ({ prompt, promptMaxLength, promptVersions, includeCost, customTaskUUID, taskUUID: _taskUUID, retry, includeGenerationTime, includePayload, }: IPromptEnhancer) => Promise<IEnhancedPrompt[]>;
    promptEnhance: (params: IPromptEnhancer) => Promise<IEnhancedPrompt[]>;
    modelUpload: (payload: TAddModel) => Promise<any>;
    photoMaker: (payload: TPhotoMaker, moreOptions?: Record<string, any>) => Promise<TPhotoMakerResponse[] | undefined>;
    modelSearch: (payload: TModelSearch) => Promise<TModelSearchResponse>;
    imageMasking: (payload: TImageMasking) => Promise<TImageMaskingResponse>;
    imageUpload: (payload: TImageUpload) => Promise<TImageUploadResponse>;
    mediaStorage: (payload: TMediaStorage) => Promise<TMediaStorageResponse>;
    protected baseSingleRequest: <T>({ payload, debugKey, isMultiple, }: {
        payload: Record<string, any>;
        debugKey: string;
        isMultiple?: boolean | undefined;
    }) => Promise<T>;
    protected baseSyncRequest: <T>({ payload, groupKey, skipResponse }: {
        payload: Record<string, any>;
        groupKey: LISTEN_TO_MEDIA_KEY;
        skipResponse?: boolean | undefined;
    }) => Promise<T>;
    ensureConnection(): Promise<unknown>;
    private getResponseWithSimilarTaskUUID;
    private getSingleMessage;
    private getMultipleMessages;
    private insertAdditionalResponse;
    private handleIncompleteImages;
    disconnect: () => Promise<void>;
    private connected;
}

declare class RunwareClient extends RunwareBase {
    constructor(props: RunwareBaseType);
}

declare class RunwareServer extends RunwareBase {
    _instantiated: boolean;
    _listeners: any[];
    _reconnectingIntervalId: null | any;
    _pingTimeout: any;
    _pongListener: any;
    constructor(props: RunwareBaseType);
    protected connect(): Promise<void>;
    protected send: (msg: Object) => void;
    protected handleClose(): void;
    protected resetConnection: () => void;
    protected heartBeat(): void;
}

declare let Runware: typeof RunwareClient | typeof RunwareServer;

export { EControlMode, EModelArchitecture, EModelConditioning, EModelFormat, EModelType, EOpenPosePreProcessor, EPhotoMakerEnum, EPreProcessor, EPreProcessorGroup, ETaskType, Environment, type GetWithPromiseAsyncCallBackType, type GetWithPromiseCallBackType, type IAddModelResponse, type IAdditionalResponsePayload, type IAsyncResults, type IAudio, type IAudioOutputFormat, type IBflProviderSettings, type IControlNet, type IControlNetGeneral, type IControlNetImage, type IControlNetPreprocess, type IControlNetWithUUID, type IEmbedding, type IEnhancedPrompt, type IError, type IErrorResponse, type IImage, type IImageToText, type IOutpaint, type IOutputFormat, type IOutputType, type IPromptEnhancer, type IProviderSettings, type IRefiner, type IRemoveImage, type IRemoveImageBackground, type IRequestAudio, type IRequestImage, type IRequestImageToText, type IRequestVideo, type ITextToImage, type IUpscaleGan, type IVideoOutputFormat, type IVideoToImage, type IipAdapter, type ListenerType, type MediaUUID, type ProviderSettings, type ReconnectingWebsocketProps, type RequireAtLeastOne, type RequireOnlyOne, Runware, type RunwareBaseType, RunwareClient, RunwareServer, SdkType, type TAcceleratorOptions, type TAddModel, type TAddModelBaseType, type TAddModelCheckPoint, type TAddModelControlNet, type TAddModelLora, type TImageMasking, type TImageMaskingResponse, type TImageUpload, type TImageUploadResponse, type TMediaStorage, type TMediaStorageResponse, type TModel, type TModelSearch, type TModelSearchResponse, type TPhotoMaker, type TPhotoMakerResponse, type TPromptWeighting, type TServerError, type TVectorize, type TVectorizeResponse, type UploadImageType };
